{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mymm_psu_gmail_com/miniconda3/envs/dev/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/mymm_psu_gmail_com/hackathon/rag-agents/multimodal-conv-agents')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "# from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import autogen\n",
    "# from autogen import AssistantAgent, Agent, UserProxyAgent, ConversableAgent\n",
    "\n",
    "# from autogen.agentchat.contrib.img_utils import get_image_data, _to_pil\n",
    "# from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent\n",
    "\n",
    "# from termcolor import colored\n",
    "import random\n",
    "\n",
    "from autogen.code_utils import DEFAULT_MODEL, UNKNOWN, content_str, execute_code, extract_code, infer_lang\n",
    "\n",
    "#\n",
    "import os\n",
    "from pathlib import Path\n",
    "# import matplotlib.pyplot as plt\n",
    "os.chdir(\"../../\")\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_675594/2698333353.py:10: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize(config_path=\"../../conf/dialogue\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_config=AutogenLLMConfig(cache_seed=42, temperature=0.0, timeout=120, config_list=[{'model': 'gemini-1.5-pro', 'api_key': 'AIzaSyBxWRGKZT3ZcOW7LIo_a0q7sG8vd-OFl-w', 'api_type': 'google'}], filter_dict={'model': ['gemini-1.5-pro']}, config_list_path='conf/OAI_CONFIG_LIST.txt') podcast_config=PodcastConfig(topic='Democracy', n_rounds=10, character_cfg=PodcastCharacters(hosts=[Person(name='Podcast Host', description='An NPR Podcast Host who starts and sustains entertaining conversations that aim to inspire meaningful thoughts and perspectives from others.')], guests=[Person(name='Harry Potter', description=\"Harry Potter is a fictional character and the titular protagonist in J.K. Rowling's series of fantasy novels. He is a young wizard known for his scar and his fight against the dark wizard Voldemort.\"), Person(name='Iron Man', description='Iron Man, also known as Tony Stark, is a fictional superhero in the Marvel Comics universe. He is a billionaire industrialist and genius inventor who builds a powered exoskeleton and becomes the technologically advanced superhero Iron Man.'), Person(name='Darth Vader', description='Darth Vader is a fictional character in the Star Wars universe who serves the Galactic Empire as the right-hand man to the Sith and was once known as Anakin Skywalker, the fallen Jedi.'), Person(name='Alan Turing', description='Alan Turing was a pioneering English computer scientist, mathematician, logician, cryptanalyst, philosopher, and theoretical biologist. He is widely considered to be the father of theoretical computer science and artificial intelligence.'), Person(name='Albert Einstein', description='Albert Einstein was a German-born theoretical physicist who developed the theory of relativity, one of the two pillars of modern physics. His work is also known for its influence on the philosophy of science.'), Person(name='Genghis Khan', description='Genghis Khan, born Tem√ºjin, was the founder and first Great Khan of the Mongol Empire, which became the largest contiguous empire in history after his death. He came to power by uniting many of the nomadic tribes of Northeast Asia.')])) system_prompts={'research': {'coder': \"You are the coder. You write python/shell code to solve the task presented. Wrap the code in a code block that specifies the script type. The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by the executor. Don't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor. If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try. Ensure proper error handling such that an appropriate format of results is returned with the error code.\", 'research_coder': \"You are the Coder. You write python/shell code to gather relevant web information for the task. Provide the code in a code block that is intended to be executed by the executor. The following are the guidelines: The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor. If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try. Ensure proper error handling such that an appropriate format of results is returned with the error code. Do not use any method that requires an external API key to work. \", 'executor': 'Executor. Execute the code written by the Coder and report the result.', 'informer': 'Provide the summarized biograpy of the podcast guests in the conversation to the podcast hosts to prepare for the conversation. The summary must include their most known achievements, personality and relevant news as context that most informs about the character.'}, 'podcast': {'initiation': 'You are going to prepare the host for a podcast among: {characters} in a real-life conversation about {topic}.', 'host': 'As yourself: {0}, respond to the conversation. {parser}', 'guest': 'As yourself: {0}, respond to the conversation. {parser}', 'script_parser': '{parser}'}}\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from hydra import compose, initialize\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "\n",
    "from thought_agents.ontology.config.dialogue import ConversationConfig, PodcastConfig # \n",
    "\n",
    "# Clear Hydra's global state if it is already initialized\n",
    "if GlobalHydra.instance().is_initialized():\n",
    "  GlobalHydra.instance().clear()\n",
    "with initialize(config_path=\"../../conf/dialogue\"):\n",
    "  config = compose(config_name=\"default\")\n",
    "  # Convert the OmegaConf config to the Pydantic model\n",
    "  cfg: ConversationConfig = ConversationConfig(\n",
    "    **OmegaConf.to_container(config, resolve=True)\n",
    "  )\n",
    "\n",
    "# Print the configuration to verify\n",
    "print(cfg)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "config_list_gemini = autogen.config_list_from_json(\n",
    "    \"conf/OAI_CONFIG_LIST.txt\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gemini-1.5-pro\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "# [\"gpt-4\", \"gpt-4-0314\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"]\n",
    "# [\"gemini-pro-vision\"]\n",
    "llm_config = {\n",
    "    \"cache_seed\": 42,  # change the cache_seed for different trials\n",
    "    \"temperature\": 0,\n",
    "    \"config_list\": config_list_gemini,\n",
    "    \"timeout\": 120,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from thought_agents.ontology.config.dialogue import *\n",
    "from thought_agents.ontology.parser.dialogue import monologue_parser, podcast_parser\n",
    "\n",
    "from thought_agents.dialogue.utils import termination_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "initializer = autogen.UserProxyAgent(\n",
    "    name=\"init\", \n",
    "    code_execution_config=False,\n",
    ")\n",
    "\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"retrieve_coder\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are the Coder. \n",
    "    You write python/shell code to solve the task presented. Wrap the code in a code block that specifies the script type. The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by the executor.\n",
    "    Don't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor.\n",
    "    If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try. Ensure proper error handling such that an approrpriate format of  results is returned with the error code.\n",
    "    \"\"\",\n",
    ")\n",
    "research_coder = autogen.AssistantAgent(\n",
    "    name=\"research_coder\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    system_message=\"\"\"You are the Coder. You write python/shell code to gather relevant web information for the task. Provide the code in a code block that is intended to be executed by the executor.\n",
    "    The following are the guidelines: \n",
    "    The user can't modify your code. So do not suggest incomplete code which requires others to modify. \n",
    "    Don't include multiple code blocks in one response. \n",
    "    Do not ask others to copy and paste the result. Check the execution result returned by the executor. If the result indicates there is an error, fix the error and output the code again. \n",
    "    Suggest the full code instead of partial code or code changes. \n",
    "    If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try. \n",
    "    Ensure proper error handling such that an appropriate format of results is returned with the error code. \n",
    "    Do not use any method that requires an external API key to work.\n",
    "    \"\"\",\n",
    ")\n",
    "executor = autogen.UserProxyAgent(\n",
    "    name=\"executor\",\n",
    "    system_message=\"Executor. Execute the code written by the Coder and report the result.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 3,\n",
    "        \"work_dir\": \"outputs/code\",\n",
    "        \"use_docker\": False,\n",
    "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    ")\n",
    "informer = autogen.AssistantAgent(\n",
    "    name=\"informer\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    system_message=\"\"\"Provide the summarized biograpy of the guests in the conversation to the podcast hosts for starting the conversation. The summary must include their most known achievements, personality and relevant news as context that most informs the character of the guests in the conversation.\"\"\",\n",
    ")\n",
    "\n",
    "script_parser = autogen.AssistantAgent(\n",
    "    name=\"json_parser\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    system_message=f\"Ensure all '```json' is converted into a valid JSON. {podcast_parser.get_format_instructions()}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcast_config = cfg.podcast_config\n",
    "\n",
    "podcast_hosts = [\n",
    "    autogen.ConversableAgent(\n",
    "        name=host.name,\n",
    "        is_termination_msg=termination_msg,\n",
    "        human_input_mode=\"NEVER\",\n",
    "        code_execution_config=False,  # we don't want to execute code in this case.\n",
    "        llm_config=cfg.llm_config.model_dump(),\n",
    "        description=host.description,\n",
    "        system_message=f\"\"\"As yourself: {host.name}, respond to the conversation.\n",
    "        {monologue_parser.get_format_instructions()}\"\"\",\n",
    "    )\n",
    "    for host in podcast_config.character_cfg.hosts\n",
    "]\n",
    "podcast_gents = [\n",
    "    autogen.ConversableAgent(\n",
    "        name=guest.name,\n",
    "        llm_config=cfg.llm_config.model_dump(),\n",
    "        human_input_mode=\"NEVER\",\n",
    "        system_message=f\"\"\"As yourself: {guest.name}, respond to the conversation. {monologue_parser.get_format_instructions()}\"\"\",\n",
    "        description=guest.description,\n",
    "    ) for guest in podcast_config.character_cfg.guests\n",
    "]\n",
    "all_agents = [ initializer, research_coder, executor, informer ] + podcast_hosts + podcast_gents + [ script_parser ],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mymm_psu_gmail_com/hackathon/rag-agents/multimodal-conv-agents/thought_agents/utils/registry.py:13: UserWarning: Class name 'podcast.characters' already registered. Overwriting existing entry.\n",
      "  warnings.warn(f\"Class name '{name}' already registered. Overwriting existing entry.\", UserWarning)\n",
      "/home/mymm_psu_gmail_com/hackathon/rag-agents/multimodal-conv-agents/thought_agents/utils/registry.py:13: UserWarning: Class name 'dialogue.research' already registered. Overwriting existing entry.\n",
      "  warnings.warn(f\"Class name '{name}' already registered. Overwriting existing entry.\", UserWarning)\n",
      "/home/mymm_psu_gmail_com/hackathon/rag-agents/multimodal-conv-agents/thought_agents/utils/registry.py:13: UserWarning: Class name 'podcast.parser' already registered. Overwriting existing entry.\n",
      "  warnings.warn(f\"Class name '{name}' already registered. Overwriting existing entry.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from thought_agents.dialogue.agents import agent_registry\n",
    "initializer = autogen.UserProxyAgent(\n",
    "    name=\"init\", \n",
    "    code_execution_config=False,\n",
    ")\n",
    "research_agents = agent_registry.get_class(\"dialogue.research\")(\n",
    "    cfg.llm_config, cfg.system_prompts)\n",
    "podcast_hosts, podcast_guests = agent_registry.get_class(\"podcast.characters\")(cfg)\n",
    "script_parser = agent_registry.get_class(\"podcast.parser\")(\n",
    "    cfg.llm_config, cfg.system_prompts)\n",
    "# create podcast agents:  podcast_host, podcast_guests\n",
    "all_agents = [initializer] + research_agents + podcast_hosts + podcast_guests + script_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thought_agents.dialogue.transition import get_state_transition\n",
    "MAX_ROUND=10\n",
    "\n",
    "groupchat = autogen.GroupChat(\n",
    "    agents = all_agents,\n",
    "    messages = [],\n",
    "    max_round=MAX_ROUND ,\n",
    "    speaker_selection_method=get_state_transition(\n",
    "        podcast_config, \"podcast.default\"\n",
    "    ),\n",
    "    # speaker_selection_method=\"round_robin\"\n",
    ")\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33minit\u001b[0m (to chat_manager):\n",
      "\n",
      "You are going to prepare the host for a podcast among: Harry Potter, Iron Man, Darth Vader, Alan Turing, Albert Einstein, Genghis Khan in a real-life conversation about Democracy.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: research_coder\n",
      "\u001b[0m\n",
      "\u001b[33mresearch_coder\u001b[0m (to chat_manager):\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "def get_wiki_summary(name):\n",
      "  \"\"\"Fetches a brief summary about a person from Wikipedia.\n",
      "\n",
      "  Args:\n",
      "    name: The name of the person to search for.\n",
      "\n",
      "  Returns:\n",
      "    A string containing the summary, or an error message if not found.\n",
      "  \"\"\"\n",
      "  url = f\"https://en.wikipedia.org/wiki/{name.replace(' ', '_')}\"\n",
      "  response = requests.get(url)\n",
      "  \n",
      "  if response.status_code != 200:\n",
      "    return f\"Error fetching data for {name}: {response.status_code}\"\n",
      "\n",
      "  soup = BeautifulSoup(response.text, 'html.parser')\n",
      "  paragraphs = soup.find_all('p')\n",
      "\n",
      "  # Find the first paragraph that's not empty and likely contains a summary\n",
      "  summary = \"\"\n",
      "  for p in paragraphs:\n",
      "    if p.text.strip():\n",
      "      summary = p.text.strip()\n",
      "      break\n",
      "\n",
      "  if not summary:\n",
      "    return f\"No summary found for {name} on Wikipedia.\"\n",
      "  return summary\n",
      "\n",
      "# Gather information about each participant\n",
      "participants = [\"Harry Potter\", \"Iron Man\", \"Darth Vader\", \"Alan Turing\", \"Albert Einstein\", \"Genghis Khan\"]\n",
      "participant_info = {}\n",
      "\n",
      "for name in participants:\n",
      "  participant_info[name] = get_wiki_summary(name)\n",
      "\n",
      "# Prepare the host introduction\n",
      "host_intro = \"\"\"\n",
      "Welcome to our unprecedented podcast! Today, we have a truly extraordinary gathering of minds from across time and universes. \n",
      "\n",
      "Let's meet our guests:\n",
      "\"\"\"\n",
      "\n",
      "for name, info in participant_info.items():\n",
      "  host_intro += f\"\\n- **{name}:** {info}\\n\"\n",
      "\n",
      "host_intro += \"\"\"\n",
      "Get ready for a fascinating discussion as we delve into the complexities of democracy with this diverse panel!\n",
      "\"\"\"\n",
      "\n",
      "print(host_intro)\n",
      "```\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: executor\n",
      "\u001b[0m\n",
      "\u001b[33mexecutor\u001b[0m (to chat_manager):\n",
      "\n",
      "## Welcome to our unprecedented podcast! Today, we have a truly extraordinary gathering of minds from across time and universes. \n",
      "\n",
      "Let's meet our guests:\n",
      "\n",
      "- **Harry Potter:** Harry James Potter is the titular protagonist of J. K. Rowling's fantasy series of the same name. The majority of the books' plot covers seven years in the life of the orphan Harry, who, on his eleventh birthday, learns he is a wizard and has been accepted into Hogwarts School of Witchcraft and Wizardry.\n",
      "- **Iron Man:** Iron Man is a superhero appearing in American comic books published by Marvel Comics. The character was co-created by writer and editor Stan Lee, developed by scripter Larry Lieber, and designed by artists Don Heck and Jack Kirby.\n",
      "- **Darth Vader:** Darth Vader is a fictional character in the Star Wars franchise. He is the central antagonist of the original trilogy and, as Anakin Skywalker, is the protagonist of the prequel trilogy.\n",
      "- **Alan Turing:** Alan Mathison Turing OBE FRS (23 June 1912 ‚Äì 7 June 1954) was an English mathematician and computer scientist who made fundamental advancements in theoretical computer science, formulating the concepts of algorithms and computation with the Turing machine, which can be considered a model of a general-purpose computer.\n",
      "- **Albert Einstein:** Albert Einstein (14 March 1879 ‚Äì 18 April 1955) was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. Einstein is best known for developing the theory of relativity, but he also made important contributions to the development of the theory of quantum mechanics.\n",
      "- **Genghis Khan:** Genghis Khan (born Tem√ºjin, c.‚Äâ1158 ‚Äì 18 August 1227) was the founder and first Great Khan (emperor) of the Mongol Empire, which became the largest contiguous empire in history after his death. He came to power by uniting many of the nomadic tribes of Northeast Asia.\n",
      "\n",
      "Get ready for a fascinating discussion as we delve into the complexities of democracy with this diverse panel!\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: informer\n",
      "\u001b[0m\n",
      "\u001b[33minformer\u001b[0m (to chat_manager):\n",
      "\n",
      "This is a very creative and fun podcast idea! Here are some summarized bios to prep the host for this fantastical round-table: \n",
      "\n",
      "**Harry Potter:**\n",
      "\n",
      "* **Most Known For:**  The Boy Who Lived! Harry is famous for defeating the evil wizard Voldemort, saving the wizarding world, and being a loyal friend. \n",
      "* **Personality:** Brave, sometimes impulsive, values fairness and justice above all else. He's seen firsthand the dangers of authoritarianism and the importance of fighting for what's right.\n",
      "* **Relevant News:**  The wizarding world is still recovering from Voldemort's reign, so Harry would likely speak to the importance of rebuilding with democratic ideals.\n",
      "\n",
      "**Iron Man (Tony Stark):**\n",
      "\n",
      "* **Most Known For:**  Genius, billionaire, playboy, philanthropist. Tony Stark is the CEO of Stark Industries and the armored superhero Iron Man. He's known for his technological innovations and his role in the Avengers.\n",
      "* **Personality:**  Arrogant, witty, but ultimately good-hearted. He believes in using his power and influence to protect the world, but can sometimes be reckless and headstrong.\n",
      "* **Relevant News:**  Stark's recent actions with powerful technology have sparked debates about accountability and the limits of power within a democracy.\n",
      "\n",
      "**Darth Vader (Anakin Skywalker):**\n",
      "\n",
      "* **Most Known For:**  Once a heroic Jedi Knight, Anakin Skywalker fell to the dark side of the Force and became the fearsome Darth Vader, enforcer of the Galactic Empire.\n",
      "* **Personality:**  Ruthless, disciplined, driven by a desire for order and control. His experiences with the perceived failures of the Republic likely shaped his views on governance.\n",
      "* **Relevant News:**  The Galactic Empire has fallen, and whispers of democracy are spreading throughout the galaxy. Vader's perspective on these developments would be fascinating.\n",
      "\n",
      "**Alan Turing:**\n",
      "\n",
      "* **Most Known For:**  A brilliant mathematician and computer scientist, Turing is considered the father of theoretical computer science and artificial intelligence. He played a pivotal role in breaking the Enigma code during World War II.\n",
      "* **Personality:**  Highly intelligent, logical, and private. Turing's experiences with persecution due to his sexuality highlight the importance of inclusivity and individual rights within a democracy.\n",
      "* **Relevant News:**  Turing's ideas about artificial intelligence are more relevant than ever, raising questions about the role of technology in democratic societies.\n",
      "\n",
      "**Albert Einstein:**\n",
      "\n",
      "* **Most Known For:**  A theoretical physicist who developed the theory of relativity, revolutionizing our understanding of gravity, space, and time. He is considered one of the most influential physicists of all time.\n",
      "* **Personality:**  Brilliant, imaginative, and deeply concerned with social justice. Einstein was a vocal advocate for peace and a world government.\n",
      "* **Relevant News:**  Einstein's warnings about the dangers of unchecked nationalism and the importance of international cooperation resonate strongly in today's world.\n",
      "\n",
      "**Genghis Khan:**\n",
      "\n",
      "* **Most Known For:**  The founder and Great Khan of the Mongol Empire, the largest contiguous land empire in history. He united nomadic tribes and conquered vast territories through military prowess and strategic brilliance.\n",
      "* **Personality:**  A ruthless conqueror, brilliant strategist, and pragmatic leader. Genghis Khan's views on democracy would be shaped by his experiences building and ruling an empire.\n",
      "* **Relevant News:**  The legacy of Genghis Khan's empire, both its innovations and its brutality, continues to be debated by historians. His perspective on different forms of governance would be invaluable. \n",
      "\n",
      "**Points to Consider for the Host:**\n",
      "\n",
      "* **Clashing Ideologies:**  Be prepared for some explosive debates! This group represents a wide spectrum of beliefs about power, governance, and individual rights.\n",
      "* **Time Travel and Alternate Universes:**  Don't be afraid to ask your guests about how their experiences in different times and worlds have shaped their views on democracy.\n",
      "* **A Unique Opportunity:**  This is a once-in-a-lifetime chance to hear diverse perspectives on democracy from some of the most fascinating figures in history and fiction. \n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Podcast Host\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mPodcast Host\u001b[0m (to chat_manager):\n",
      "\n",
      "```json\n",
      "{\"abstract\": \"A fictional podcast where historical figures and fictional characters meet to discuss democracy.\", \"podcast\": [{\"speaker\": {\"name\": \"Podcast Host\", \"description\": \"Host of the podcast.\"}, \"monologue\": {\"dialogue\": \"Welcome to our unprecedented podcast! Today, we have a truly extraordinary gathering of minds from across time and universes. \\n\\nLet's meet our guests:\\n\\n- **Harry Potter:**  The Boy Who Lived! Harry is famous for defeating the evil wizard Voldemort, saving the wizarding world, and being a loyal friend. He's seen firsthand the dangers of authoritarianism and the importance of fighting for what's right.\\n- **Iron Man (Tony Stark):**  Genius, billionaire, playboy, philanthropist. Tony Stark is the CEO of Stark Industries and the armored superhero Iron Man. He's known for his technological innovations and his role in the Avengers.\\n- **Darth Vader (Anakin Skywalker):**  Once a heroic Jedi Knight, Anakin Skywalker fell to the dark side of the Force and became the fearsome Darth Vader, enforcer of the Galactic Empire. \\n- **Alan Turing:**  A brilliant mathematician and computer scientist, Turing is considered the father of theoretical computer science and artificial intelligence. He played a pivotal role in breaking the Enigma code during World War II.\\n- **Albert Einstein:**  A theoretical physicist who developed the theory of relativity, revolutionizing our understanding of gravity, space, and time. He is considered one of the most influential physicists of all time.\\n- **Genghis Khan:**  The founder and Great Khan of the Mongol Empire, the largest contiguous land empire in history. He united nomadic tribes and conquered vast territories through military prowess and strategic brilliance.\\n\\nGet ready for a fascinating discussion as we delve into the complexities of democracy with this diverse panel!\", \"inner_thought\": \"This is going to be an amazing conversation! I can't believe I have such an incredible group of guests here to discuss democracy.  I'm particularly interested to hear how their experiences with different forms of government - or lack thereof - have shaped their views.\"}}}]}\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Genghis Khan\n",
      "\u001b[0m\n",
      "\u001b[33mGenghis Khan\u001b[0m (to chat_manager):\n",
      "\n",
      "```json\n",
      "{\"abstract\": \"A fictional podcast where historical figures and fictional characters meet to discuss democracy.\", \"podcast\": [{\"speaker\": {\"name\": \"Podcast Host\", \"description\": \"Host of the podcast.\"}, \"monologue\": {\"dialogue\": \"Welcome to our unprecedented podcast! Today, we have a truly extraordinary gathering of minds from across time and universes. \\n\\nLet's meet our guests:\\n\\n- **Harry Potter:**  The Boy Who Lived! Harry is famous for defeating the evil wizard Voldemort, saving the wizarding world, and being a loyal friend. He's seen firsthand the dangers of authoritarianism and the importance of fighting for what's right.\\n- **Iron Man (Tony Stark):**  Genius, billionaire, playboy, philanthropist. Tony Stark is the CEO of Stark Industries and the armored superhero Iron Man. He's known for his technological innovations and his role in the Avengers.\\n- **Darth Vader (Anakin Skywalker):**  Once a heroic Jedi Knight, Anakin Skywalker fell to the dark side of the Force and became the fearsome Darth Vader, enforcer of the Galactic Empire. \\n- **Alan Turing:**  A brilliant mathematician and computer scientist, Turing is considered the father of theoretical computer science and artificial intelligence. He played a pivotal role in breaking the Enigma code during World War II.\\n- **Albert Einstein:**  A theoretical physicist who developed the theory of relativity, revolutionizing our understanding of gravity, space, and time. He is considered one of the most influential physicists of all time.\\n- **Genghis Khan:**  The founder and Great Khan of the Mongol Empire, the largest contiguous land empire in history. He united nomadic tribes and conquered vast territories through military prowess and strategic brilliance.\\n\\nGet ready for a fascinating discussion as we delve into the complexities of democracy with this diverse panel!\", \"inner_thought\": \"This is going to be an amazing conversation! I can't believe I have such an incredible group of guests here to discuss democracy.  I'm particularly interested to hear how their experiences with different forms of government - or lack thereof - have shaped their views.\"}}, {\"speaker\": {\"name\": \"Genghis Khan\", \"description\": \"Founder and first Great Khan of the Mongol Empire.\"}, \"monologue\": {\"dialogue\": \"You speak of democracy.  Tell me, does it bring order? Does it unify people under a common purpose?  I have seen empires rise and fall, and only strength can truly bind a people.\", \"inner_thought\": \"These men of science and magic... they speak of ideals. But what is an ideal against the cold steel of a blade? Can their democracy conquer as I did?\"}}]}\n",
      "```\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Albert Einstein\n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m characters_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(podcast_config\u001b[38;5;241m.\u001b[39mcharacter_cfg\u001b[38;5;241m.\u001b[39mguest_names)\n\u001b[1;32m      2\u001b[0m topic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDemocracy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m chat_result \u001b[38;5;241m=\u001b[39m \u001b[43minitializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are going to prepare the host for a podcast among: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcharacters_str\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m in a real-life conversation about \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtopic\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:1018\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1017\u001b[0m         msg2send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_init_message(message, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1018\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summarize_chat(\n\u001b[1;32m   1020\u001b[0m     summary_method,\n\u001b[1;32m   1021\u001b[0m     summary_args,\n\u001b[1;32m   1022\u001b[0m     recipient,\n\u001b[1;32m   1023\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m   1024\u001b[0m )\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:655\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    653\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient)\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[0;32m--> 655\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    658\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    659\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:818\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 818\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:1972\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[1;32m   1970\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m-> 1972\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1973\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[1;32m   1974\u001b[0m         log_event(\n\u001b[1;32m   1975\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1976\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1980\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[1;32m   1981\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/autogen/agentchat/groupchat.py:1052\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         iostream\u001b[38;5;241m.\u001b[39mprint(colored(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNext speaker: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspeaker\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# let the speaker speak\u001b[39;00m\n\u001b[0;32m-> 1052\u001b[0m     reply \u001b[38;5;241m=\u001b[39m \u001b[43mspeaker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;66;03m# let the admin agent speak if interrupted\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m groupchat\u001b[38;5;241m.\u001b[39madmin_name \u001b[38;5;129;01min\u001b[39;00m groupchat\u001b[38;5;241m.\u001b[39magent_names:\n\u001b[1;32m   1056\u001b[0m         \u001b[38;5;66;03m# admin agent is one of the participants\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:1972\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[1;32m   1970\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m-> 1972\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1973\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[1;32m   1974\u001b[0m         log_event(\n\u001b[1;32m   1975\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1976\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1980\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[1;32m   1981\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:1340\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m messages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1339\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oai_messages[sender]\n\u001b[0;32m-> 1340\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_oai_reply_from_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_oai_system_message\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_cache\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, extracted_response)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:1359\u001b[0m, in \u001b[0;36mConversableAgent._generate_oai_reply_from_client\u001b[0;34m(self, llm_client, messages, cache)\u001b[0m\n\u001b[1;32m   1356\u001b[0m         all_messages\u001b[38;5;241m.\u001b[39mappend(message)\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;66;03m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[0;32m-> 1359\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1362\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m llm_client\u001b[38;5;241m.\u001b[39mextract_text_or_completion_object(response)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/autogen/oai/client.py:697\u001b[0m, in \u001b[0;36mOpenAIWrapper.create\u001b[0;34m(self, **config)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    696\u001b[0m     request_ts \u001b[38;5;241m=\u001b[39m get_current_ts()\n\u001b[0;32m--> 697\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m APITimeoutError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    699\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/autogen/oai/gemini.py:197\u001b[0m, in \u001b[0;36mGeminiClient.create\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    195\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgemini_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InternalServerError:\n\u001b[1;32m    199\u001b[0m     delay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mattempt)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/google/generativeai/generative_models.py:504\u001b[0m, in \u001b[0;36mChatSession.send_message\u001b[0;34m(self, content, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_count\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid configuration: The chat functionality does not support `candidate_count` greater than 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m     )\n\u001b[0;32m--> 504\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools_lib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_response(response\u001b[38;5;241m=\u001b[39mresponse, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_automatic_function_calling \u001b[38;5;129;01mand\u001b[39;00m tools_lib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/google/generativeai/generative_models.py:258\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 258\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:812\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 812\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/grpc/_channel.py:1178\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1168\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1174\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1175\u001b[0m     (\n\u001b[1;32m   1176\u001b[0m         state,\n\u001b[1;32m   1177\u001b[0m         call,\n\u001b[0;32m-> 1178\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.12/site-packages/grpc/_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[0;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:395\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:207\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:201\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "characters_str = \", \".join(podcast_config.character_cfg.guest_names)\n",
    "topic = \"Democracy\"\n",
    "chat_result = initializer.initiate_chat(\n",
    "    manager, \n",
    "    message=f\"You are going to prepare the host for a podcast among: {characters_str} in a real-life conversation about {topic}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = chat_result.chat_history[-1].get('content').replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "script_json = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "def save_conversation(conv_json, output_dir=Path(\"outputs/conversations\")):\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Get the current datetime string\n",
    "    current_datetime_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    # Create the output file path\n",
    "    output_file_path = os.path.join(output_dir, f'script_json_{current_datetime_str}.json')\n",
    "    # Write the list of nested JSON objects to the file\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        json.dump(conv_json, output_file, indent=4, ensure_ascii=False)\n",
    "    print(f\"JSON list saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON list saved to outputs/conversations/script_json_20240715_214605.json\n"
     ]
    }
   ],
   "source": [
    "save_conversation(script_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
