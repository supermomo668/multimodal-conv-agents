{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev2Lg0x0wdO5"
      },
      "source": [
        "# SocietyOfMindAgent\n",
        "\n",
        "This notebook demonstrates the SocietyOfMindAgent, which runs a group chat as an internal monologue, but appears to the external world as a single agent. This confers three distinct advantages:\n",
        "\n",
        "1. It provides a clean way of producing a hierarchy of agents, hiding complexity as inner monologues.\n",
        "2. It provides a consistent way of extracting an answer from a lengthy group chat (normally, it is not clear which message is the final response, and the response itself may not always be formatted in a way that makes sense when extracted as a standalone message).\n",
        "3. It provides a way of recovering when agents exceed their context window constraints (the inner monologue is protected by try-catch blocks)\n",
        "\n",
        "````{=mdx}\n",
        ":::info Requirements\n",
        "Install `pyautogen`:\n",
        "```bash\n",
        "pip install pyautogen\n",
        "```\n",
        "\n",
        "For more information, please refer to the [installation guide](/docs/installation/).\n",
        ":::\n",
        "````"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/mymm_psu_gmail_com/hackathon/rag-agents/multimodal-conv-agents\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "os.chdir(\"../../\")\n",
        "print(Path.cwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tl-kD1XXwdO_"
      },
      "outputs": [],
      "source": [
        "import autogen  # noqa: E402\n",
        "config_list_gemini = autogen.config_list_from_json(\n",
        "    \"conf/OAI_CONFIG_LIST.txt\",\n",
        "    filter_dict={\n",
        "        \"model\": [\"gemini-pro\"]\n",
        "        # , \"gpt-4\", \"gpt-4-0613\", \"gpt-4-32k\", \"gpt-4-32k-0613\", \"gpt-4-1106-preview\"],\n",
        "    },\n",
        ")\n",
        "\n",
        "llm_config = {\n",
        "    \"timeout\": 600,\n",
        "    \"cache_seed\": 44,  # change the seed for different trials\n",
        "    \"config_list\": config_list_gemini,\n",
        "    \"temperature\": 0,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqna61JDwdPB"
      },
      "source": [
        "````{=mdx}\n",
        ":::tip\n",
        "Learn more about configuring LLMs for agents [here](/docs/topics/llm_configuration).\n",
        ":::\n",
        "````\n",
        "\n",
        "### Example Group Chat with Two Agents\n",
        "\n",
        "In this example, we will use an AssistantAgent and a UserProxy agent (configured for code execution) to work together to solve a problem. Executing code requires *at least* two conversation turns (one to write the code, and one to execute the code). If the code fails, or needs further refinement, then additional turns may also be needed. When will then wrap these agents in a SocietyOfMindAgent, hiding the internal discussion from other agents (though will still appear in the console), and ensuring that the response is suitable as a standalone message."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFcIlH7XwdPB"
      },
      "source": [
        "#### Construct the Inner-Monologue Agents\n",
        "We begin by constructing the inner-monologue agents. These are the agents that do that real work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JzIgFoujwdPB",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "assistant = autogen.AssistantAgent(\n",
        "    \"inner-assistant\",\n",
        "    llm_config=llm_config,\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"TERMINATE\") >= 0,\n",
        ")\n",
        "\n",
        "code_interpreter = autogen.UserProxyAgent(\n",
        "    \"inner-code-interpreter\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    code_execution_config={\n",
        "        \"work_dir\": \"coding\",\n",
        "        \"use_docker\": False,\n",
        "    },\n",
        "    default_auto_reply=\"\",\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"TERMINATE\") >= 0,\n",
        ")\n",
        "\n",
        "groupchat = autogen.GroupChat(\n",
        "    agents=[assistant, code_interpreter],\n",
        "    messages=[],\n",
        "    speaker_selection_method=\"round_robin\",  # With two agents, this is equivalent to a 1:1 conversation.\n",
        "    allow_repeat_speaker=False,\n",
        "    max_round=8,\n",
        ")\n",
        "\n",
        "manager = autogen.GroupChatManager(\n",
        "    groupchat=groupchat,\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"TERMINATE\") >= 0,\n",
        "    llm_config=llm_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHabvEMewdPC"
      },
      "source": [
        "#### Construct and Run the SocietyOfMind Agent\n",
        "We now wrap the inner group-chat with the SocietyOfMind Agent, and create a UserProxy to talk to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_0vrU0JTwdPC",
        "outputId": "2a960b40-7f49-49e6-bd8b-5ec01f539d82"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "SocietyOfMindAgent.__init__() got an unexpected keyword argument 'system_message'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautogen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magentchat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msociety_of_mind_agent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SocietyOfMindAgent  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m      3\u001b[0m task \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the best path for the galaxy?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m society_of_mind_agent \u001b[38;5;241m=\u001b[39m \u001b[43mSocietyOfMindAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mre Obi-wan Kenobi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchat_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReply in JSON\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m user_proxy \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mUserProxyAgent(\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_proxy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     human_input_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEVER\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     is_termination_msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m )\n",
            "\u001b[0;31mTypeError\u001b[0m: SocietyOfMindAgent.__init__() got an unexpected keyword argument 'system_message'"
          ]
        }
      ],
      "source": [
        "from autogen.agentchat.contrib.society_of_mind_agent import SocietyOfMindAgent  # noqa: E402\n",
        "\n",
        "task = \"What is the best path for the galaxy?\"\n",
        "\n",
        "society_of_mind_agent = SocietyOfMindAgent(\n",
        "    \"You're Obi-wan Kenobi\",\n",
        "    chat_manager=manager,\n",
        "    llm_config=llm_config,\n",
        ")\n",
        "\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    \"user_proxy\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    system_message=\"Reply in JSON\",\n",
        "    code_execution_config=False,\n",
        "    default_auto_reply=\"\",\n",
        "    is_termination_msg=lambda x: True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33muser_proxy\u001b[0m (to Obi-wan Kenobi):\n",
            "\n",
            "What is the best path for the galaxy?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[31m\n",
            ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
            "\u001b[33mObi-wan Kenobi\u001b[0m (to chat_manager):\n",
            "\n",
            "What is the best path for the galaxy?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33minner-assistant\u001b[0m (to chat_manager):\n",
            "\n",
            "```sh\n",
            "ls -1 /etc | grep galaxy\n",
            "```\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[31m\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...\u001b[0m\n",
            "\u001b[33minner-code-interpreter\u001b[0m (to chat_manager):\n",
            "\n",
            "exitcode: 1 (execution failed)\n",
            "Code output: \n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33minner-assistant\u001b[0m (to chat_manager):\n",
            "\n",
            "```sh\n",
            "df | grep -i galaxy\n",
            "```\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[31m\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...\u001b[0m\n",
            "\u001b[33minner-code-interpreter\u001b[0m (to chat_manager):\n",
            "\n",
            "exitcode: 1 (execution failed)\n",
            "Code output: \n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33minner-assistant\u001b[0m (to chat_manager):\n",
            "\n",
            "Based on the output of the previous command, it appears that the 'galaxy' directory is not mounted on the system. As a result, we cannot provide the best path for the galaxy.\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mObi-wan Kenobi\u001b[0m (to user_proxy):\n",
            "\n",
            "{'content': \"Unfortunately, the 'galaxy' directory is not mounted on this system, so I cannot provide the best path for the galaxy.\", 'role': 'assistant', 'function_call': None, 'tool_calls': None}\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ChatResult(chat_id=None, chat_history=[{'content': 'What is the best path for the galaxy?', 'role': 'assistant'}, {'content': '{\\'content\\': \"Unfortunately, the \\'galaxy\\' directory is not mounted on this system, so I cannot provide the best path for the galaxy.\", \\'role\\': \\'assistant\\', \\'function_call\\': None, \\'tool_calls\\': None}', 'role': 'user'}], summary='{\\'content\\': \"Unfortunately, the \\'galaxy\\' directory is not mounted on this system, so I cannot provide the best path for the galaxy.\", \\'role\\': \\'assistant\\', \\'function_call\\': None, \\'tool_calls\\': None}', cost={'usage_including_cached_inference': {'total_cost': 0.000225, 'gemini-pro': {'cost': 0.000225, 'prompt_tokens': 300, 'completion_tokens': 50, 'total_tokens': 350}}, 'usage_excluding_cached_inference': {'total_cost': 0.0001125, 'gemini-pro': {'cost': 0.0001125, 'prompt_tokens': 150, 'completion_tokens': 25, 'total_tokens': 175}}}, human_input=[])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_proxy.initiate_chat(society_of_mind_agent, message=task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkBiCS3NwdPE"
      },
      "source": [
        "#### Remarks\n",
        "\n",
        "There are a few things to notice about this output:\n",
        "- First, the user_proxy sent only one message to the society_of_mind agent, and received only one message in response. As far as it is concerned, the society_of_mind agent is the only agent in the chat.\n",
        "- Second, the final response is formatted in a way that is standalone. Unlike the prior response, it makes no reference of a previous script or execution, and it lacks the TERMINATE keyword that ended the inner monologue."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "front_matter": {
      "description": "Explore the demonstration of the SocietyOfMindAgent in the AutoGen library, which runs a group chat as an internal monologue, but appears to the external world as a single agent, offering a structured way to manage complex interactions among multiple agents and handle issues such as extracting responses from complex dialogues and dealing with context window constraints.",
      "tags": [
        "orchestration",
        "nested chat"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
