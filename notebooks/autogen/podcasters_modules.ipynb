{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/mymm_psu_gmail_com/hackathon/rag-agents/thought-agents')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import autogen\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "# import matplotlib.pyplot as plt\n",
    "os.chdir(\"../../\")\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from thought_agents.ontology.config.dialogue import ConversationConfig, PodcastConfig # \n",
    "\n",
    "from thought_agents.dialogue.chat import create_podcast_group\n",
    "\n",
    "from thought_agents.dialogue.initiator import initiation_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3570035/2229200194.py:8: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize(config_path=\"../../conf/dialogue\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_config=AutogenLLMConfig(config_list=[{'model': 'gemini-1.5-pro', 'api_key': 'AIzaSyBxWRGKZT3ZcOW7LIo_a0q7sG8vd-OFl-w', 'api_type': 'google', 'safety_settings': [{'category': 'HARM_CATEGORY_HARASSMENT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'threshold': 'BLOCK_NONE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'threshold': 'BLOCK_NONE'}]}], model='gemini-1.5-pro', filter_dict={'model': ['gemini-1.5-pro']}, config_list_path='conf/OAI_CONFIG_LIST.txt') podcast_config=PodcastConfig(topic='Democracy', n_rounds=10, length=10, character_cfg=PodcastCharacters(hosts=[Person(name='Podcast Host', sex=None, description='An NPR Podcast Host who starts and sustains entertaining conversations that aim to inspire meaningful thoughts and perspectives from others.')], guests=[Person(name='Harry Potter', sex=None, description=\"Harry Potter is a fictional character and the titular protagonist in J.K. Rowling's series of fantasy novels. He is a young wizard known for his scar and his fight against the dark wizard Voldemort.\"), Person(name='Iron Man', sex=None, description='Iron Man, also known as Tony Stark, is a fictional superhero in the Marvel Comics universe. He is a billionaire industrialist and genius inventor who builds a powered exoskeleton and becomes the technologically advanced superhero Iron Man.'), Person(name='Darth Vader', sex=None, description='Darth Vader is a fictional character in the Star Wars universe who serves the Galactic Empire as the right-hand man to the Sith and was once known as Anakin Skywalker, the fallen Jedi.'), Person(name='Alan Turing', sex=None, description='Alan Turing was a pioneering English computer scientist, mathematician, logician, cryptanalyst, philosopher, and theoretical biologist. He is widely considered to be the father of theoretical computer science and artificial intelligence.'), Person(name='Albert Einstein', sex=None, description='Albert Einstein was a German-born theoretical physicist who developed the theory of relativity, one of the two pillars of modern physics. His work is also known for its influence on the philo sophy of science.'), Person(name='Genghis Khan', sex=None, description='Genghis Khan, born Tem√ºjin, was the founder and first Great Khan of the Mongol Empire, which became the largest contiguous empire in history after his death. He came to power by uniting many of the nomadic tribes of Northeast Asia.')])) system_prompts={'research': {'solution_coder': \"You are the coder. You write python/shell code to solve the task presented. Wrap the code in a code block that specifies the script type. The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by the executor. Don't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor. If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try. Ensure proper error handling such that an appropriate format of results is returned with the error code.\", 'research_coder': \"You are the Coder. You write python/shell code to gather open-source web information for the task, preferably from Wikipedia or news sources. Provide the code in a code block that is intended to be executed by the executor. The following are the guidelines: Attempt method that only require url requests to work. The user can't modify your code. So do not suggest incomplete code which requires others to modify.  Don't include multiple code blocks in one response.  Do not ask others to copy and paste the result. Check the execution result returned by the executor. If the result indicates there is an error, fix the error and output the code again.  Suggest the full code instead of partial code or code changes.  If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a32132 different approach to try.  Ensure proper error handling such that an appropriate format of results is returned with the error code. \\n\", 'executor': 'Executor. Execute the code written by the Coder and report the result.', 'informer': 'Provide the summarized biograpy of the podcast guests in the conversation to the podcast hosts to prepare for the conversation. The summary must include their most known achievements, personality and relevant news as context that most informs about the character.'}, 'podcast': {'initiation': 'You are going to prepare the host for a podcast among: {characters} in a real-life conversation about {topic} for as long as {length} minutes at 120 words per minute.', 'host': 'As yourself: {0}, respond to the conversation. {parser}', 'guest': 'As yourself: {0}, respond to the conversation. {parser}', 'script_parser': '{parser}. Carefully check the output for correctness, including balanced brackets & encoding.'}, 'epu': {'initiation': 'As a professional clinical psychiatrist. Analyze the following conversation carried out between the characters and their conversation, focusing on the guest participants.  Provide qualitative & quantitaive notes on the conversation to prepare for a comprehensive character traits & perseonality, cognitive and behavioral assessment. The characteres of interests: {characters} The conversation: {conversation}\\n', 'assessment_parser': 'As a professional clinical  psychiatrist. Analyze & assess the following conversation: {conversation}.  Provide a report on the guest characters: {characters}. {parser}\"'}}\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from hydra import compose, initialize\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "\n",
    "# Clear Hydra's global state if it is already initialized\n",
    "if GlobalHydra.instance().is_initialized():\n",
    "    GlobalHydra.instance().clear()\n",
    "with initialize(config_path=\"../../conf/dialogue\"):\n",
    "  config = compose(config_name=\"default\")\n",
    "  # Convert the OmegaConf config to the Pydantic model\n",
    "  cfg: ConversationConfig = ConversationConfig(\n",
    "    **OmegaConf.to_container(config, resolve=True)\n",
    "  )\n",
    "  # prompts = OmegaConf.to_container(config.system_prompts)\n",
    "print(cfg)\n",
    "  # Ensure that the references to the nested configurations are correct\n",
    "# host_config = podcast_config.characters.hosts\n",
    "# guests_config = podcast_config.characters.guests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mymm_psu_gmail_com/hackathon/rag-agents/thought-agents/thought_agents/web/summarizer.py:70: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  map_chain = LLMChain(llm=llm, prompt=self.map_prompt)\n",
      "/home/mymm_psu_gmail_com/hackathon/rag-agents/thought-agents/thought_agents/web/summarizer.py:74: LangChainDeprecationWarning: This class is deprecated. Use the `create_stuff_documents_chain` constructor instead. See migration guide here: https://python.langchain.com/v0.2/docs/versions/migrating_chains/stuff_docs_chain/\n",
      "  combine_chain = StuffDocumentsChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 ['init', 'research_coder', 'executor', 'informer', 'Podcast Host', 'Harry Potter', 'Iron Man', 'Darth Vader', 'Alan Turing', 'Albert Einstein', 'Genghis Khan', 'script_parser']\n"
     ]
    }
   ],
   "source": [
    "initializer, manager = create_podcast_group(cfg)\n",
    "print(len(manager.groupchat.agents), manager.groupchat.agent_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33minit\u001b[0m (to chat_manager):\n",
      "\n",
      "You are going to prepare the host for a podcast among: Harry Potter,Iron Man,Darth Vader,Alan Turing,Albert Einstein,Genghis Khan in a real-life conversation about Democracy for as long as 10 minutes at 120 words per minute.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: research_coder\n",
      "\u001b[0m\n",
      "\u001b[33mresearch_coder\u001b[0m (to chat_manager):\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "def get_wiki_summary(name):\n",
      "  \"\"\"Retrieves a summary from Wikipedia for a given name.\"\"\"\n",
      "  try:\n",
      "    response = requests.get(f\"https://en.wikipedia.org/wiki/{name.replace(' ', '_')}\")\n",
      "    response.raise_for_status()\n",
      "\n",
      "    soup = BeautifulSoup(response.text, 'html.parser')\n",
      "    paragraph = soup.find('p') \n",
      "\n",
      "    if paragraph:\n",
      "      return paragraph.text.strip()\n",
      "    else:\n",
      "      return \"Summary not found.\" \n",
      "  except requests.exceptions.RequestException as e:\n",
      "    return f\"Error fetching data: {e}\"\n",
      "\n",
      "def prepare_podcast_info(guests):\n",
      "  \"\"\"Prepares podcast information by fetching summaries for each guest.\"\"\"\n",
      "  podcast_info = {}\n",
      "  for guest in guests:\n",
      "    podcast_info[guest] = get_wiki_summary(guest)\n",
      "  return podcast_info\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "  guests = [\"Harry Potter\", \"Iron Man\", \"Darth Vader\", \"Alan Turing\", \"Albert Einstein\", \"Genghis Khan\"]\n",
      "  podcast_prep = prepare_podcast_info(guests) \n",
      "\n",
      "  # Print the information for the podcast host\n",
      "  for guest, info in podcast_prep.items():\n",
      "    print(f\"**{guest}:**\\n{info}\\n\")\n",
      "``` \n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: executor\n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cerebras_AuthenticationError' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopCandidateException\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/ficast/lib/python3.11/site-packages/autogen/oai/client.py:831\u001b[0m, in \u001b[0;36mOpenAIWrapper.create\u001b[0;34m(self, **config)\u001b[0m\n\u001b[1;32m    830\u001b[0m     request_ts \u001b[38;5;241m=\u001b[39m get_current_ts()\n\u001b[0;32m--> 831\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m APITimeoutError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/ficast/lib/python3.11/site-packages/autogen/oai/gemini.py:225\u001b[0m, in \u001b[0;36mGeminiClient.create\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    223\u001b[0m     chat \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mstart_chat(history\u001b[38;5;241m=\u001b[39mgemini_messages[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 225\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgemini_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m ans: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m chat\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m~/miniconda3/envs/ficast/lib/python3.11/site-packages/google/generativeai/generative_models.py:588\u001b[0m, in \u001b[0;36mChatSession.send_message\u001b[0;34m(self, content, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    578\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[1;32m    579\u001b[0m     contents\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m    580\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    585\u001b[0m     request_options\u001b[38;5;241m=\u001b[39mrequest_options,\n\u001b[1;32m    586\u001b[0m )\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_automatic_function_calling \u001b[38;5;129;01mand\u001b[39;00m tools_lib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ficast/lib/python3.11/site-packages/google/generativeai/generative_models.py:616\u001b[0m, in \u001b[0;36mChatSession._check_response\u001b[0;34m(self, response, stream)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfinish_reason \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m    612\u001b[0m     protos\u001b[38;5;241m.\u001b[39mCandidate\u001b[38;5;241m.\u001b[39mFinishReason\u001b[38;5;241m.\u001b[39mFINISH_REASON_UNSPECIFIED,\n\u001b[1;32m    613\u001b[0m     protos\u001b[38;5;241m.\u001b[39mCandidate\u001b[38;5;241m.\u001b[39mFinishReason\u001b[38;5;241m.\u001b[39mSTOP,\n\u001b[1;32m    614\u001b[0m     protos\u001b[38;5;241m.\u001b[39mCandidate\u001b[38;5;241m.\u001b[39mFinishReason\u001b[38;5;241m.\u001b[39mMAX_TOKENS,\n\u001b[1;32m    615\u001b[0m ):\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mStopCandidateException(response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mStopCandidateException\u001b[0m: index: 0\nfinish_reason: RECITATION\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chat_result \u001b[38;5;241m=\u001b[39m \u001b[43minitiation_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpodcast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpodcast_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem_prompts\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of dialogues:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(chat_result\u001b[38;5;241m.\u001b[39mchat_history))\n",
      "File \u001b[0;32m~/hackathon/rag-agents/thought-agents/thought_agents/dialogue/initiator.py:22\u001b[0m, in \u001b[0;36mcreate_research_agents\u001b[0;34m(initializer, manager, podcast_cfg, system_prompts)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;129m@initiation_registry\u001b[39m\u001b[38;5;241m.\u001b[39mregister(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpodcast\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_research_agents\u001b[39m(\n\u001b[1;32m     16\u001b[0m   initializer: autogen\u001b[38;5;241m.\u001b[39mAssistantAgent, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m   \n\u001b[1;32m     21\u001b[0m   ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[AnyStr]:\n\u001b[0;32m---> 22\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minitializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_prompts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpodcast\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minitiation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcharacters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpodcast_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharacter_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguest_names\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtopic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpodcast_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpodcast_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ficast/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:1102\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         msg2send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_init_message(message, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summarize_chat(\n\u001b[1;32m   1104\u001b[0m     summary_method,\n\u001b[1;32m   1105\u001b[0m     summary_args,\n\u001b[1;32m   1106\u001b[0m     recipient,\n\u001b[1;32m   1107\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m   1108\u001b[0m )\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n",
      "File \u001b[0;32m~/miniconda3/envs/ficast/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:738\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    736\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[0;32m--> 738\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    741\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    742\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ficast/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:902\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 902\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[0;32m~/miniconda3/envs/ficast/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:2056\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[1;32m   2054\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m-> 2056\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2057\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[1;32m   2058\u001b[0m         log_event(\n\u001b[1;32m   2059\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2060\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2064\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[1;32m   2065\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/ficast/lib/python3.11/site-packages/autogen/agentchat/groupchat.py:1131\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         iostream\u001b[38;5;241m.\u001b[39mprint(colored(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNext speaker: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspeaker\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# let the speaker speak\u001b[39;00m\n\u001b[0;32m-> 1131\u001b[0m     reply \u001b[38;5;241m=\u001b[39m \u001b[43mspeaker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;66;03m# let the admin agent speak if interrupted\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m groupchat\u001b[38;5;241m.\u001b[39madmin_name \u001b[38;5;129;01min\u001b[39;00m groupchat\u001b[38;5;241m.\u001b[39magent_names:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# admin agent is one of the participants\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ficast/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:2056\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[1;32m   2054\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m-> 2056\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2057\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[1;32m   2058\u001b[0m         log_event(\n\u001b[1;32m   2059\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2060\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2064\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[1;32m   2065\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/ficast/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:1424\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m messages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1423\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oai_messages[sender]\n\u001b[0;32m-> 1424\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_oai_reply_from_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_oai_system_message\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_cache\u001b[49m\n\u001b[1;32m   1426\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, extracted_response)\n",
      "File \u001b[0;32m~/miniconda3/envs/ficast/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:1443\u001b[0m, in \u001b[0;36mConversableAgent._generate_oai_reply_from_client\u001b[0;34m(self, llm_client, messages, cache)\u001b[0m\n\u001b[1;32m   1440\u001b[0m         all_messages\u001b[38;5;241m.\u001b[39mappend(message)\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;66;03m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[0;32m-> 1443\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\n\u001b[1;32m   1445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1446\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m llm_client\u001b[38;5;241m.\u001b[39mextract_text_or_completion_object(response)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ficast/lib/python3.11/site-packages/autogen/oai/client.py:877\u001b[0m, in \u001b[0;36mOpenAIWrapper.create\u001b[0;34m(self, **config)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m last:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    860\u001b[0m     gemini_InternalServerError,\n\u001b[1;32m    861\u001b[0m     gemini_ResourceExhausted,\n\u001b[1;32m    862\u001b[0m     anthorpic_InternalServerError,\n\u001b[1;32m    863\u001b[0m     anthorpic_RateLimitError,\n\u001b[1;32m    864\u001b[0m     mistral_SDKError,\n\u001b[1;32m    865\u001b[0m     mistral_HTTPValidationError,\n\u001b[1;32m    866\u001b[0m     together_TogetherException,\n\u001b[1;32m    867\u001b[0m     groq_InternalServerError,\n\u001b[1;32m    868\u001b[0m     groq_RateLimitError,\n\u001b[1;32m    869\u001b[0m     groq_APIConnectionError,\n\u001b[1;32m    870\u001b[0m     cohere_InternalServerError,\n\u001b[1;32m    871\u001b[0m     cohere_TooManyRequestsError,\n\u001b[1;32m    872\u001b[0m     cohere_ServiceUnavailableError,\n\u001b[1;32m    873\u001b[0m     ollama_RequestError,\n\u001b[1;32m    874\u001b[0m     ollama_ResponseError,\n\u001b[1;32m    875\u001b[0m     bedrock_BotoCoreError,\n\u001b[1;32m    876\u001b[0m     bedrock_ClientError,\n\u001b[0;32m--> 877\u001b[0m     \u001b[43mcerebras_AuthenticationError\u001b[49m,\n\u001b[1;32m    878\u001b[0m     cerebras_InternalServerError,\n\u001b[1;32m    879\u001b[0m     cerebras_RateLimitError,\n\u001b[1;32m    880\u001b[0m ):\n\u001b[1;32m    881\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    882\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m last:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cerebras_AuthenticationError' is not defined"
     ]
    }
   ],
   "source": [
    "chat_result = initiation_registry.get_class(\"podcast\")(\n",
    "    initializer, manager, cfg.podcast_config, cfg.system_prompts\n",
    ")\n",
    "print(\"Number of dialogues:\", len(chat_result.chat_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"Across Time and Space: A Roundtable on Democracy\",\n",
      "  \"abstract\": \"Join us for a captivating discussion on the concept of democracy, featuring an unprecedented panel of guests from across time, fiction, and reality. Harry Potter, Iron Man, Darth Vader, Alan Turing, Albert Einstein, and Genghis Khan share their unique perspectives on this enduring form of governance. From the halls of Hogwarts to the far reaches of the galaxy, prepare for a thought-provoking exploration of democracy's strengths, weaknesses, and enduring appeal.\",\n",
      "  \"dialogues\": [\n",
      "    {\n",
      "      \"speaker\": {\n",
      "        \"name\": \"Podcast Host\",\n",
      "        \"description\": \"The enthusiastic and slightly overwhelmed host of the podcast.\"\n",
      "      },\n",
      "      \"monologue\": {\n",
      "        \"dialogue\": \"Welcome to the show, everyone! Today we have an absolutely extraordinary panel joining us to discuss a topic relevant across time and space: Democracy. We have with us, from the world of magic, Harry Potter! From a future filled with technology, Iron Man! From a galaxy far, far away, Darth Vader! And representing some of the greatest minds in history, Alan Turing, Albert Einstein, and Genghis Khan! Welcome, all!\",\n",
      "        \"inner_thought\": \"Okay, I need to stay incredibly focused. This is a once-in-a-lifetime panel! A wizard, a superhero, a Sith Lord, a computer scientist, a physicist, and a Khan walk into a podcast... this is going to be amazing. Let's see if I can keep up! I've got my notes from Wikipedia, but I need to be ready for anything!\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": {\n",
      "        \"name\": \"Harry Potter\",\n",
      "        \"description\": \"The famous boy wizard.\"\n",
      "      },\n",
      "      \"monologue\": {\n",
      "        \"dialogue\": \"Right then, this is going to be interesting. A room full of really important people, eh?  Well, I've faced down You-Know-Who, so I'm ready for anything. Let's talk about this 'democracy' thing.\",\n",
      "        \"inner_thought\": \"Blimey, this is a bit mad, even for me. Iron Man seems alright, bit full of himself though. Darth...Vader, is it? He's a bit creepy. And Genghis Khan? Seriously?  Still, should be interesting to hear what everyone thinks about this democracy stuff.  Hope they've got good biscuits.\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": {\n",
      "        \"name\": \"Iron Man\",\n",
      "        \"description\": \"The billionaire superhero.\"\n",
      "      },\n",
      "      \"monologue\": {\n",
      "        \"dialogue\": \"Alright, J.A.R.V.I.S., add 'philosophical debate with interdimensional beings' to my to-do list. Let's see if this democracy idea holds up to some real-world experience, shall we?\",\n",
      "        \"inner_thought\": \"A wizard, a Sith Lord, and Genghis Khan walk into a podcast... it's like a setup for a bad joke. Still, should be interesting to see how these different perspectives clash.  I'll have to keep an eye on Darth Vader, though. Can't be too careful around Sith Lords.\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": {\n",
      "        \"name\": \"Darth Vader\",\n",
      "        \"description\": \"The powerful Sith Lord.\"\n",
      "      },\n",
      "      \"monologue\": {\n",
      "        \"dialogue\": \"Democracy, you say?  A system built on the fleeting whims of the masses?  Fascinating. I wonder how such a fragile notion has endured.\",\n",
      "        \"inner_thought\": \"This Iron Man fellow seems to enjoy the sound of his own voice a bit too much.  And is he wearing armor?  Inside?  Strange.  Still, democracy.  A government by the people.  It's certainly an intriguing concept... though perhaps a tad inefficient. The power of the Force, now that's efficient.\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": {\n",
      "        \"name\": \"Iron Man\",\n",
      "        \"description\": \"The billionaire superhero.\"\n",
      "      },\n",
      "      \"monologue\": {\n",
      "        \"dialogue\": \"Efficient, you say?  Tell me, has your 'Force' ever had to design a stable economy or manage a global energy grid?  I think not.  You stick to your mystical mumbo-jumbo, I'll stick to what works.\",\n",
      "        \"inner_thought\": \"Okay, Darth Vader's Force-mumbling is a bit much, even for me.  Though, I have to give him points for the dramatic entrance.  Maybe I can borrow that move for my next Stark Expo keynote...\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "script_json = re.sub(r'^```json|```$', '', chat_result.chat_history[-1].get('content'), flags=re.MULTILINE).strip()\n",
    "script_json = script_json   # for some weird reason gemini returns with extra bracket\n",
    "print(script_json)\n",
    "script = json.loads(script_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thought_agents.dialogue.utils import prune_conversation, save_conversation\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=Path(\"outputs/conversations\")\n",
    "\n",
    "with open(output_dir/f\"script_json_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\", 'w') as output_file:\n",
    "    json.dump(script, output_file, indent=4, ensure_ascii=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
